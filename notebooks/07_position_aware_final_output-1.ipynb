{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 7 — Position-Aware Final Output\n",
        "\n",
        "Turn scored candidates into the final 8–10 items for the UI:\n",
        "\n",
        "- **Position 1:** anchor head score or D-t-D override (engagement hook)\n",
        "- **Positions 2–10:** remaining by full business score\n",
        "- **Explanation:** one-line for position 1 from top contributing feature\n",
        "- **Cap:** max 200 candidates enter ranking → output top 8–10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What Step 7 is doing**\n",
        "\n",
        "- **Input:** Scored candidates per session (business_score + anchor_score from Step 5).\n",
        "- **1. Cap:** Only the top 200 candidates by business score are kept; the rest are dropped to keep the pipeline fast and bounded.\n",
        "- **2. Step 6:** The capped list goes through post-ranking (diversity, category mix, price shock, margin cap, time-of-day, D-t-D). If a distance-to-discount nudge applies, Step 6 already puts that item at position 1 with its message.\n",
        "- **3. Position 1:** If there was no D-t-D override, we set position 1 to the item with the **highest anchor_score** (the model that predicts \"accepted when shown at position 1\"), so the best \"hook\" is always in slot 1.\n",
        "- **4. Positions 2–10:** The remaining slots stay ordered by **full business score** (blend of accept, AOV, abandon, timing, anchor).\n",
        "- **5. Explanation:** The position-1 item gets a one-line explanation from the top contributing feature (e.g. beverage/dessert/bread gap, complement, bestseller, or the D-t-D nudge text).\n",
        "\n",
        "**Files used:** Existing data and models only (no new files in `data/` or `models/`). Step 7 logic lives in `position_aware_output.py`; `__pycache__` is created automatically when that module is imported."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys, os\n",
        "sys.path.insert(0, os.path.abspath(\"..\"))\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from position_aware_output import position_aware_final_output, MAX_CANDIDATES_FOR_RANKING, DEFAULT_RAIL_SIZE\n",
        "\n",
        "DATA_DIR = os.path.abspath(\"../data\")\n",
        "MODEL_DIR = os.path.abspath(\"../models\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 7 — Position-Aware Final Output\n",
        "\n",
        "Turn scored candidates into the final 8–10 items for the UI:\n",
        "\n",
        "- **Position 1:** anchor head score or D-t-D override (engagement hook)\n",
        "- **Positions 2–10:** remaining by full business score\n",
        "- **Explanation:** one-line for position 1 from top contributing feature\n",
        "- **Cap:** max 200 candidates enter ranking → output top 8–10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 7 logic is in `position_aware_output.py` (see imports above). It caps candidates at 200, runs Step 6 post-ranking, then sets position 1 to D-t-D override or best anchor; positions 2–10 by business score; one-line explanation for position 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run Step 7 on sample sessions\n",
        "np.random.seed(42)\n",
        "sids = np.random.choice(test_df[\"session_id\"].unique(), size=min(100, test_df[\"session_id\"].nunique()), replace=False)\n",
        "results = []\n",
        "for sid in sids:\n",
        "    sess = test_df[test_df[\"session_id\"] == sid].copy()\n",
        "    if len(sess) < 3:\n",
        "        continue\n",
        "    ct, cs = sess[\"cart_total_value\"].iloc[0], int(sess[\"cart_size\"].iloc[0])\n",
        "    pm = sess[\"peak_hour_mode\"].iloc[0]\n",
        "    rail, st = position_aware_final_output(sess, ct, cs, pm, rail_size=DEFAULT_RAIL_SIZE)\n",
        "    results.append({\"session_id\": sid, **st})\n",
        "\n",
        "stats_df = pd.DataFrame(results)\n",
        "print(f\"Sessions: {len(stats_df)}\")\n",
        "print(f\"Input → after_cap → output: {stats_df['input'].mean():.0f} → {stats_df['after_cap'].mean():.0f} → {stats_df['output'].iloc[0]}\")\n",
        "print(f\"Position 1 from D-t-D override: {(stats_df['dtd_override']==1).sum()} sessions\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Before vs after Step 7 — position 1 and explanation**\n",
        "\n",
        "For one session: (A) top 10 by business score only vs (B) after Step 7 (position 1 = anchor or D-t-D, with explanation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What Step 7 is doing**\n",
        "\n",
        "- **Input:** Scored candidates per session (business_score + anchor_score from Step 5).\n",
        "- **1. Cap:** Only the top 200 candidates by business score are kept; the rest are dropped to keep the pipeline fast and bounded.\n",
        "- **2. Step 6:** The capped list goes through post-ranking (diversity, category mix, price shock, margin cap, time-of-day, D-t-D). If a distance-to-discount nudge applies, Step 6 already puts that item at position 1 with its message.\n",
        "- **3. Position 1:** If there was no D-t-D override, we set position 1 to the item with the **highest anchor_score** (the model that predicts \"accepted when shown at position 1\"), so the best \"hook\" is always in slot 1.\n",
        "- **4. Positions 2–10:** The remaining slots stay ordered by **full business score** (blend of accept, AOV, abandon, timing, anchor).\n",
        "- **5. Explanation:** The position-1 item gets a one-line explanation from the top contributing feature (e.g. beverage/dessert/bread gap, complement, bestseller, or the D-t-D nudge text).\n",
        "\n",
        "**Files used:** Existing data and models only (no new files in `data/` or `models/`). Step 7 logic lives in `position_aware_output.py`; `__pycache__` is created automatically when that module is imported."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Position 1 source** — % of sessions where position 1 came from D-t-D override vs from anchor score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys, os\n",
        "sys.path.insert(0, os.path.abspath(\"..\"))\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from position_aware_output import position_aware_final_output, MAX_CANDIDATES_FOR_RANKING, DEFAULT_RAIL_SIZE\n",
        "\n",
        "DATA_DIR = os.path.abspath(\"../data\")\n",
        "MODEL_DIR = os.path.abspath(\"../models\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation types** — Distribution of position-1 explanation text (from top contributing feature or D-t-D nudge)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Collect position-1 explanation for each session in sample\n",
        "explanation_counts = []\n",
        "for sid in stats_df[\"session_id\"]:\n",
        "    sess = test_df[test_df[\"session_id\"] == sid].copy()\n",
        "    if len(sess) < 3:\n",
        "        continue\n",
        "    ct, cs = sess[\"cart_total_value\"].iloc[0], int(sess[\"cart_size\"].iloc[0])\n",
        "    rail, _ = position_aware_final_output(sess, ct, cs, sess[\"peak_hour_mode\"].iloc[0])\n",
        "    expl = rail.iloc[0].get(\"explanation\", \"\") or \"\"\n",
        "    explanation_counts.append(expl)\n",
        "expl_series = pd.Series(explanation_counts).value_counts()\n",
        "print(\"Position-1 explanation distribution:\")\n",
        "display(expl_series.head(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Cap impact** — Max 200 candidates enter ranking; output is top 8–10. Below: one session where the cap applies (if any), else summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sessions with most candidates (cap applies when input > 200)\n",
        "cap_example = stats_df.loc[stats_df[\"input\"].idxmax()]\n",
        "print(f\"Session with most candidates: {cap_example['input']} → after cap: {cap_example['after_cap']} → output: {cap_example['output']}\")\n",
        "if cap_example[\"input\"] > MAX_CANDIDATES_FOR_RANKING:\n",
        "    print(f\"Cap applied: {cap_example['input']} candidates trimmed to {MAX_CANDIDATES_FOR_RANKING} before Step 6.\")\n",
        "else:\n",
        "    print(f\"No session in sample had >{MAX_CANDIDATES_FOR_RANKING} candidates; cap applies when candidate pool is larger.\")\n",
        "print(f\"\\nAcross sample: input mean = {stats_df['input'].mean():.0f}, after_cap mean = {stats_df['after_cap'].mean():.0f}, output = {stats_df['output'].iloc[0]} items\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Step 7 flow** — Scored candidates → Cap 200 → Step 6 post-rank → Position 1 (D-t-D or anchor) → Pos 2–10 by biz score → Rail 8–10 + explanation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example: one session final rail\n",
        "sid = sids[0]\n",
        "sess = test_df[test_df[\"session_id\"] == sid].copy()\n",
        "ct, cs = sess[\"cart_total_value\"].iloc[0], int(sess[\"cart_size\"].iloc[0])\n",
        "rail, _ = position_aware_final_output(sess, ct, cs, sess[\"peak_hour_mode\"].iloc[0])\n",
        "display(rail[[\"rank\", \"item_name\", \"item_category\", \"item_price\", \"business_score\", \"explanation\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Step 7 done.** Position 1 = anchor or D-t-D; 2–10 by business score; explanation from top feature; max 200 candidates → top 8–10. Logic in `position_aware_output.py`; uses existing data and models (no new files in `data/` or `models/`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load data, models, prepare features, score test set\n",
        "from lgbm_ranker import (\n",
        "    engineer_labels, prepare_features, temporal_split,\n",
        "    compute_business_score, load_models,\n",
        ")\n",
        "features = pd.read_csv(f\"{DATA_DIR}/training_features.csv\")\n",
        "sessions = pd.read_csv(f\"{DATA_DIR}/sessions.csv\")\n",
        "menu = pd.read_csv(f\"{DATA_DIR}/menu_items.csv\")\n",
        "gru_hidden = np.load(f\"{DATA_DIR}/gru_hidden_states.npy\")\n",
        "\n",
        "features = engineer_labels(features)\n",
        "features, feature_cols, encoders = prepare_features(features, gru_hidden)\n",
        "_, _, test_mask = temporal_split(features, sessions)\n",
        "models = load_models()\n",
        "\n",
        "test_df = features[test_mask].copy()\n",
        "preds = {n: m.predict(test_df[feature_cols]) for n, m in models.items()}\n",
        "test_df[\"business_score\"] = compute_business_score(preds)\n",
        "test_df[\"anchor_score\"] = preds[\"anchor\"]\n",
        "\n",
        "for col in [\"item_category\", \"item_subcategory\", \"peak_hour_mode\"]:\n",
        "    if col in encoders:\n",
        "        test_df[col] = encoders[col].inverse_transform(test_df[col].astype(int))\n",
        "test_df[\"item_name\"] = test_df[\"item_id\"].map(menu.set_index(\"item_id\")[\"name\"])\n",
        "\n",
        "print(f\"Scored test set: {len(test_df):,} rows\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 7 logic is in `position_aware_output.py` (see imports above). It caps candidates at 200, runs Step 6 post-ranking, then sets position 1 to D-t-D override or best anchor; positions 2–10 by business score; one-line explanation for position 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run Step 7 on sample sessions\n",
        "np.random.seed(42)\n",
        "sids = np.random.choice(test_df[\"session_id\"].unique(), size=min(100, test_df[\"session_id\"].nunique()), replace=False)\n",
        "results = []\n",
        "for sid in sids:\n",
        "    sess = test_df[test_df[\"session_id\"] == sid].copy()\n",
        "    if len(sess) < 3:\n",
        "        continue\n",
        "    ct, cs = sess[\"cart_total_value\"].iloc[0], int(sess[\"cart_size\"].iloc[0])\n",
        "    pm = sess[\"peak_hour_mode\"].iloc[0]\n",
        "    rail, st = position_aware_final_output(sess, ct, cs, pm, rail_size=DEFAULT_RAIL_SIZE)\n",
        "    results.append({\"session_id\": sid, **st})\n",
        "\n",
        "stats_df = pd.DataFrame(results)\n",
        "print(f\"Sessions: {len(stats_df)}\")\n",
        "print(f\"Input → after_cap → output: {stats_df['input'].mean():.0f} → {stats_df['after_cap'].mean():.0f} → {stats_df['output'].iloc[0]}\")\n",
        "print(f\"Position 1 from D-t-D override: {(stats_df['dtd_override']==1).sum()} sessions\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Before vs after Step 7 — position 1 and explanation**\n",
        "\n",
        "For one session: (A) top 10 by business score only vs (B) after Step 7 (position 1 = anchor or D-t-D, with explanation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 7 — Position-Aware Final Output\n",
        "\n",
        "Turn scored candidates into the final 8–10 items for the UI:\n",
        "- **Position 1:** anchor head score or D-t-D override (engagement hook)\n",
        "- **Positions 2–10:** remaining by full business score\n",
        "- **Explanation:** one-line for position 1 from top contributing feature\n",
        "- **Cap:** max 200 candidates enter ranking → output top 8–10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Position 1 source** — % of sessions where position 1 came from D-t-D override vs from anchor score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dtd_pct = 100 * (stats_df[\"dtd_override\"] == 1).mean()\n",
        "anchor_pct = 100 - dtd_pct\n",
        "print(f\"Anchor (position-1 score): {anchor_pct:.1f}%  |  D-t-D override: {dtd_pct:.1f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What Step 7 is doing**\n",
        "\n",
        "- **Input:** Scored candidates per session (business_score + anchor_score from Step 5).\n",
        "- **1. Cap:** Only the top 200 candidates by business score are kept; the rest are dropped to keep the pipeline fast and bounded.\n",
        "- **2. Step 6:** The capped list goes through post-ranking (diversity, category mix, price shock, margin cap, time-of-day, D-t-D). If a distance-to-discount nudge applies, Step 6 already puts that item at position 1 with its message.\n",
        "- **3. Position 1:** If there was no D-t-D override, we set position 1 to the item with the **highest anchor_score** (the model that predicts “accepted when shown at position 1”), so the best “hook” is always in slot 1.\n",
        "- **4. Positions 2–10:** The remaining slots stay ordered by **full business score** (blend of accept, AOV, abandon, timing, anchor).\n",
        "- **5. Explanation:** The position-1 item gets a one-line explanation from the top contributing feature (e.g. beverage/dessert/bread gap, complement, bestseller, or the D-t-D nudge text).\n",
        "\n",
        "**Files used:** Existing data and models only (no new files in `data/` or `models/`). Step 7 logic lives in `position_aware_output.py`; `__pycache__` is created automatically when that module is imported."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Collect position-1 explanation for each session in sample\n",
        "explanation_counts = []\n",
        "for sid in stats_df[\"session_id\"]:\n",
        "    sess = test_df[test_df[\"session_id\"] == sid].copy()\n",
        "    if len(sess) < 3:\n",
        "        continue\n",
        "    ct, cs = sess[\"cart_total_value\"].iloc[0], int(sess[\"cart_size\"].iloc[0])\n",
        "    rail, _ = position_aware_final_output(sess, ct, cs, sess[\"peak_hour_mode\"].iloc[0])\n",
        "    expl = rail.iloc[0].get(\"explanation\", \"\") or \"\"\n",
        "    explanation_counts.append(expl)\n",
        "expl_series = pd.Series(explanation_counts).value_counts()\n",
        "print(\"Position-1 explanation distribution:\")\n",
        "display(expl_series.head(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Cap impact** — Max 200 candidates enter ranking; output is top 8–10. Below: one session where the cap applies (if any), else summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys, os\n",
        "sys.path.insert(0, os.path.abspath(\"..\"))\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from position_aware_output import position_aware_final_output, MAX_CANDIDATES_FOR_RANKING, DEFAULT_RAIL_SIZE\n",
        "\n",
        "DATA_DIR = os.path.abspath(\"../data\")\n",
        "MODEL_DIR = os.path.abspath(\"../models\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Step 7 flow** — Scored candidates → Cap 200 → Step 6 post-rank → Position 1 (D-t-D or anchor) → Pos 2–10 by biz score → Rail 8–10 + explanation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example: one session final rail\n",
        "sid = sids[0]\n",
        "sess = test_df[test_df[\"session_id\"] == sid].copy()\n",
        "ct, cs = sess[\"cart_total_value\"].iloc[0], int(sess[\"cart_size\"].iloc[0])\n",
        "rail, _ = position_aware_final_output(sess, ct, cs, sess[\"peak_hour_mode\"].iloc[0])\n",
        "display(rail[[\"rank\", \"item_name\", \"item_category\", \"item_price\", \"business_score\", \"explanation\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Step 7 done.** Position 1 = anchor or D-t-D; 2–10 by business score; explanation from top feature; max 200 candidates → top 8–10. Logic in `position_aware_output.py`; uses existing data and models (no new files in `data/` or `models/`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load data, models, prepare features, score test set\n",
        "from lgbm_ranker import (\n",
        "    engineer_labels, prepare_features, temporal_split,\n",
        "    compute_business_score, load_models,\n",
        ")\n",
        "features = pd.read_csv(f\"{DATA_DIR}/training_features.csv\")\n",
        "sessions = pd.read_csv(f\"{DATA_DIR}/sessions.csv\")\n",
        "menu = pd.read_csv(f\"{DATA_DIR}/menu_items.csv\")\n",
        "gru_hidden = np.load(f\"{DATA_DIR}/gru_hidden_states.npy\")\n",
        "\n",
        "features = engineer_labels(features)\n",
        "features, feature_cols, encoders = prepare_features(features, gru_hidden)\n",
        "_, _, test_mask = temporal_split(features, sessions)\n",
        "models = load_models()\n",
        "\n",
        "test_df = features[test_mask].copy()\n",
        "preds = {n: m.predict(test_df[feature_cols]) for n, m in models.items()}\n",
        "test_df[\"business_score\"] = compute_business_score(preds)\n",
        "test_df[\"anchor_score\"] = preds[\"anchor\"]\n",
        "\n",
        "for col in [\"item_category\", \"item_subcategory\", \"peak_hour_mode\"]:\n",
        "    if col in encoders:\n",
        "        test_df[col] = encoders[col].inverse_transform(test_df[col].astype(int))\n",
        "test_df[\"item_name\"] = test_df[\"item_id\"].map(menu.set_index(\"item_id\")[\"name\"])\n",
        "\n",
        "print(f\"Scored test set: {len(test_df):,} rows\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "dlopen(/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/lightgbm/lib/lib_lightgbm.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\n  Referenced from: <D44045CD-B874-3A27-9A61-F131D99AACE4> /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/lightgbm/lib/lib_lightgbm.dylib\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/local/lib/libomp/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/local/lib/libomp/libomp.dylib' (no such file)",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load data, models, prepare features, score test set\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlgbm_ranker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     engineer_labels, prepare_features, temporal_split,\n\u001b[32m      4\u001b[39m     compute_business_score, load_models,\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m features = pd.read_csv(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/training_features.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m sessions = pd.read_csv(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/sessions.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/app/zomato-hackathon--1/lgbm_ranker.py:33\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional, Tuple\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlgb\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/lightgbm/__init__.py:11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# .basic is intentionally loaded as early as possible, to dlopen() lib_lightgbm.{dll,dylib,so}\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# and its dependencies as early as possible\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbasic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Booster, Dataset, Sequence, register_logger\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopException, early_stopping, log_evaluation, record_evaluation, reset_parameter\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CVBooster, cv, train\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/lightgbm/basic.py:9\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33;03m\"\"\"Wrapper for C API of LightGBM.\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# This import causes lib_lightgbm.{dll,dylib,so} to be loaded.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# It's intentionally done here, as early as possible, to avoid issues like\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# \"libgomp.so.1: cannot allocate memory in static TLS block\" on aarch64 Linux.\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# For details, see the \"cannot allocate memory in static TLS block\" entry in docs/FAQ.rst.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlibpath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LIB  \u001b[38;5;66;03m# isort: skip\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mabc\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mctypes\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/lightgbm/libpath.py:49\u001b[39m\n\u001b[32m     47\u001b[39m     _LIB = Mock(ctypes.CDLL)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     _LIB = \u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcdll\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLoadLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_find_lib_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ctypes/__init__.py:460\u001b[39m, in \u001b[36mLibraryLoader.LoadLibrary\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mLoadLibrary\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dlltype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ctypes/__init__.py:379\u001b[39m, in \u001b[36mCDLL.__init__\u001b[39m\u001b[34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[39m\n\u001b[32m    376\u001b[39m \u001b[38;5;28mself\u001b[39m._FuncPtr = _FuncPtr\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle = \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    381\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle = handle\n",
            "\u001b[31mOSError\u001b[39m: dlopen(/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/lightgbm/lib/lib_lightgbm.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\n  Referenced from: <D44045CD-B874-3A27-9A61-F131D99AACE4> /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/lightgbm/lib/lib_lightgbm.dylib\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/local/lib/libomp/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/local/lib/libomp/libomp.dylib' (no such file)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Step 7 logic is in position_aware_output.py (see imports above)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run Step 7 on sample sessions\n",
        "np.random.seed(42)\n",
        "sids = np.random.choice(test_df[\"session_id\"].unique(), size=min(100, test_df[\"session_id\"].nunique()), replace=False)\n",
        "results = []\n",
        "for sid in sids:\n",
        "    sess = test_df[test_df[\"session_id\"] == sid].copy()\n",
        "    if len(sess) < 3:\n",
        "        continue\n",
        "    ct, cs = sess[\"cart_total_value\"].iloc[0], int(sess[\"cart_size\"].iloc[0])\n",
        "    pm = sess[\"peak_hour_mode\"].iloc[0]\n",
        "    rail, st = position_aware_final_output(sess, ct, cs, pm, rail_size=DEFAULT_RAIL_SIZE)\n",
        "    results.append({\"session_id\": sid, **st})\n",
        "\n",
        "stats_df = pd.DataFrame(results)\n",
        "print(f\"Sessions: {len(stats_df)}\")\n",
        "print(f\"Input → after_cap → output: {stats_df['input'].mean():.0f} → {stats_df['after_cap'].mean():.0f} → {stats_df['output'].iloc[0]}\")\n",
        "print(f\"Position 1 from D-t-D override: {(stats_df['dtd_override']==1).sum()} sessions\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sessions: 50\n",
            "Input → after_cap → output: 13 → 13 → 5\n",
            "Position 1 from D-t-D override: 0 sessions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Before vs after Step 7 — position 1 and explanation**\n",
        "\n",
        "For one session: (A) top 10 by business score only vs (B) after Step 7 (position 1 = anchor or D-t-D, with explanation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Same session: before Step 7 (top 10 by business score) vs after Step 7 (position 1 = anchor or D-t-D + explanation)\n",
        "sid = sids[0]\n",
        "sess = test_df[test_df[\"session_id\"] == sid].copy()\n",
        "ct, cs = sess[\"cart_total_value\"].iloc[0], int(sess[\"cart_size\"].iloc[0])\n",
        "pm = sess[\"peak_hour_mode\"].iloc[0]\n",
        "\n",
        "before = sess.sort_values(\"business_score\", ascending=False).head(10).reset_index(drop=True)\n",
        "before[\"rank\"] = range(1, len(before) + 1)\n",
        "rail_after, st = position_aware_final_output(sess, ct, cs, pm)\n",
        "\n",
        "print(\"Before Step 7 — top 10 by business score only (position 1 = highest business_score):\")\n",
        "display(before[[\"rank\", \"item_name\", \"item_category\", \"business_score\"]].head(5))\n",
        "print(\"\\nAfter Step 7 — position 1 = anchor or D-t-D; one-line explanation for slot 1:\")\n",
        "display(rail_after[[\"rank\", \"item_name\", \"item_category\", \"business_score\", \"explanation\"]].head(5))\n",
        "print(f\"\\nPosition 1 changed: {before.iloc[0]['item_name']} → {rail_after.iloc[0]['item_name']}\")\n",
        "print(f\"Explanation for position 1: \\\"{rail_after.iloc[0]['explanation']}\\\"\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before Step 7 — top 10 by business score only (position 1 = highest business_score):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rank</th>\n",
              "      <th>item_name</th>\n",
              "      <th>item_category</th>\n",
              "      <th>business_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Kesari Bath</td>\n",
              "      <td>main</td>\n",
              "      <td>0.333094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Mint Raita</td>\n",
              "      <td>beverage</td>\n",
              "      <td>0.330736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Laccha Paratha</td>\n",
              "      <td>appetizer</td>\n",
              "      <td>0.322490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Roasted Papad</td>\n",
              "      <td>beverage</td>\n",
              "      <td>0.207021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Rajma Masala</td>\n",
              "      <td>beverage</td>\n",
              "      <td>0.112070</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rank       item_name item_category  business_score\n",
              "0     1     Kesari Bath          main        0.333094\n",
              "1     2      Mint Raita      beverage        0.330736\n",
              "2     3  Laccha Paratha     appetizer        0.322490\n",
              "3     4   Roasted Papad      beverage        0.207021\n",
              "4     5    Rajma Masala      beverage        0.112070"
            ]
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "After Step 7 — position 1 = anchor or D-t-D; one-line explanation for slot 1:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rank</th>\n",
              "      <th>item_name</th>\n",
              "      <th>item_category</th>\n",
              "      <th>business_score</th>\n",
              "      <th>explanation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Mint Raita</td>\n",
              "      <td>beverage</td>\n",
              "      <td>0.330736</td>\n",
              "      <td>Recommended for you!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Kesari Bath</td>\n",
              "      <td>main</td>\n",
              "      <td>0.333094</td>\n",
              "      <td>Recommended for you!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Laccha Paratha</td>\n",
              "      <td>appetizer</td>\n",
              "      <td>0.322490</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Roasted Papad</td>\n",
              "      <td>beverage</td>\n",
              "      <td>0.207021</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Rajma Masala</td>\n",
              "      <td>beverage</td>\n",
              "      <td>0.112070</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rank       item_name item_category  business_score           explanation\n",
              "0     1      Mint Raita      beverage        0.330736  Recommended for you!\n",
              "1     2     Kesari Bath          main        0.333094  Recommended for you!\n",
              "2     3  Laccha Paratha     appetizer        0.322490                      \n",
              "3     4   Roasted Papad      beverage        0.207021                      \n",
              "4     5    Rajma Masala      beverage        0.112070                      "
            ]
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Position 1 changed: Kesari Bath → Mint Raita\n",
            "Explanation for position 1: \"Recommended for you!\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Position 1 source** — % of sessions where position 1 came from D-t-D override vs from anchor score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dtd_pct = 100 * (stats_df[\"dtd_override\"] == 1).mean()\n",
        "anchor_pct = 100 - dtd_pct\n",
        "print(f\"Anchor (position-1 score): {anchor_pct:.1f}%  |  D-t-D override: {dtd_pct:.1f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation types** — Distribution of position-1 explanation text (from top contributing feature or D-t-D nudge)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Collect position-1 explanation for each session in sample\n",
        "explanation_counts = []\n",
        "for sid in stats_df[\"session_id\"]:\n",
        "    sess = test_df[test_df[\"session_id\"] == sid].copy()\n",
        "    if len(sess) < 3:\n",
        "        continue\n",
        "    ct, cs = sess[\"cart_total_value\"].iloc[0], int(sess[\"cart_size\"].iloc[0])\n",
        "    rail, _ = position_aware_final_output(sess, ct, cs, sess[\"peak_hour_mode\"].iloc[0])\n",
        "    expl = rail.iloc[0].get(\"explanation\", \"\") or \"\"\n",
        "    explanation_counts.append(expl)\n",
        "expl_series = pd.Series(explanation_counts).value_counts()\n",
        "print(\"Position-1 explanation distribution:\")\n",
        "display(expl_series.head(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Cap impact** — Max 200 candidates enter ranking; output is top 8–10. Below: one session where the cap applies (if any), else summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sessions with most candidates (cap applies when input > 200)\n",
        "cap_example = stats_df.loc[stats_df[\"input\"].idxmax()]\n",
        "print(f\"Session with most candidates: {cap_example['input']} → after cap: {cap_example['after_cap']} → output: {cap_example['output']}\")\n",
        "if cap_example[\"input\"] > MAX_CANDIDATES_FOR_RANKING:\n",
        "    print(f\"Cap applied: {cap_example['input']} candidates trimmed to {MAX_CANDIDATES_FOR_RANKING} before Step 6.\")\n",
        "else:\n",
        "    print(f\"No session in sample had >{MAX_CANDIDATES_FOR_RANKING} candidates; cap applies when candidate pool is larger.\")\n",
        "print(f\"\\nAcross sample: input mean = {stats_df['input'].mean():.0f}, after_cap mean = {stats_df['after_cap'].mean():.0f}, output = {stats_df['output'].iloc[0]} items\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Step 7 flow** — Scored candidates → Cap 200 → Step 6 post-rank → Position 1 (D-t-D or anchor) → Pos 2–10 by biz score → Rail 8–10 + explanation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Step 7 pipeline (text summary; see markdown above for flow)\n",
        "pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example: one session final rail\n",
        "sid = sids[0]\n",
        "sess = test_df[test_df[\"session_id\"] == sid].copy()\n",
        "ct, cs = sess[\"cart_total_value\"].iloc[0], int(sess[\"cart_size\"].iloc[0])\n",
        "rail, _ = position_aware_final_output(sess, ct, cs, sess[\"peak_hour_mode\"].iloc[0])\n",
        "display(rail[[\"rank\", \"item_name\", \"item_category\", \"item_price\", \"business_score\", \"explanation\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Step 7 done.** Position 1 = anchor or D-t-D; 2–10 by business score; explanation from top feature; max 200 candidates → top 8–10. Logic in `position_aware_output.py`; uses existing data and models (no new files in `data/` or `models/`)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}